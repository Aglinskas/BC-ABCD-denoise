{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f6ab9dff-d773-49cb-912a-6ae6504e3126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Apr 16 04:39:16 PM EDT 2025\n"
     ]
    }
   ],
   "source": [
    "!date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "75d54a12-4725-4338-b580-2301a89dcd0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/projects/sccn/andromeda1/aglinska/BC-ABCD-denoise-2/Code'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "14796ecd-3ebc-4123-a466-40c785910f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ants\n",
    "from matplotlib import pyplot as plt\n",
    "import pickle\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "43086ba9-8407-4dfd-94e3-05bc81f9a440",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pickle(fn):\n",
    "    if os.path.exists(fn):\n",
    "        with open(fn, 'rb') as file:\n",
    "            loaded_dict = pickle.load(file)\n",
    "    return loaded_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "99c40165-e7b3-45bd-9f7d-2cf0318d9d47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indir = '../Data/StudyForrest/fmriprep/'\n",
    "subs = [s for s in os.listdir(indir) if all((s.startswith('sub'),not s.endswith('.html')))]\n",
    "n = len(subs)\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "63635acd-31ce-432a-a84d-e4f39e5e2e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_name = 'DeepCor-Forrest-face-v1'\n",
    "#analysis_name = 'YuOrig-00-orig'\n",
    "analysis_dir = os.path.join('../Data/StudyForrest/ensembles_last_CVAE/',analysis_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bd9cdac0-47ab-4641-9cb0-3c89af02a571",
   "metadata": {},
   "outputs": [],
   "source": [
    "events_fn_temp = '../Data/StudyForrest/events/{sub}_ses-localizer_task-objectcategories_run-{r}_events.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f78ee232-1f0b-4c44-9dcd-a2df6c7ba58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlate_columns(arr1, arr2):\n",
    "    \"\"\"\n",
    "    Computes the Pearson correlation between corresponding columns of two matrices.\n",
    "    \n",
    "    Parameters:\n",
    "    arr1 (np.ndarray): First matrix of shape (370, 1000)\n",
    "    arr2 (np.ndarray): Second matrix of shape (370, 1000)\n",
    "    \n",
    "    Returns:\n",
    "    np.ndarray: 1D array of correlations for each column (size 1000)\n",
    "    \"\"\"\n",
    "    # Ensure input arrays are numpy arrays\n",
    "    arr1 = np.asarray(arr1)\n",
    "    arr2 = np.asarray(arr2)\n",
    "    \n",
    "    # Subtract the mean of each column (normalize)\n",
    "    arr1_centered = arr1 - np.mean(arr1, axis=0)\n",
    "    arr2_centered = arr2 - np.mean(arr2, axis=0)\n",
    "    \n",
    "    # Compute the numerator (covariance)\n",
    "    numerator = np.sum(arr1_centered * arr2_centered, axis=0)\n",
    "    \n",
    "    # Compute the denominator (product of standard deviations)\n",
    "    denominator = np.sqrt(np.sum(arr1_centered**2, axis=0) * np.sum(arr2_centered**2, axis=0))\n",
    "    \n",
    "    # Compute the Pearson correlation for each column\n",
    "    correlation = numerator / denominator\n",
    "    \n",
    "    return correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7cd951c6-0611-44ad-8a31-b4be9beabe8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_signal_maps(s,r):\n",
    "    ofn_med = os.path.join(analysis_dir,f'signal_S{s}_R{r}_med.nii.gz')\n",
    "    ofn_avg = os.path.join(analysis_dir,f'signal_S{s}_R{r}_avg.nii.gz')\n",
    "\n",
    "    if not all([os.path.exists(ofn_med),os.path.exists(ofn_avg)]):\n",
    "        signal_maps_fns = [os.path.join(analysis_dir,f) for f in os.listdir(analysis_dir) if f.startswith(f'signal_S{s}_R{r}_rep_')]\n",
    "        signal_maps_fns.sort()\n",
    "        signal_maps = [ants.image_read(signal_maps_fn) for signal_maps_fn in signal_maps_fns]\n",
    "        arr = np.array([signal_map.numpy() for signal_map in signal_maps])\n",
    "        signal_maps[0].new_image_like(np.median(arr,axis=0)).to_filename(ofn_med)\n",
    "        signal_maps[0].new_image_like(np.average(arr,axis=0)).to_filename(ofn_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7ec7e8e9-aa04-4db3-b22d-9efb74ac38eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_regs(events_fn):\n",
    "    from nilearn.glm.first_level import make_first_level_design_matrix\n",
    "\n",
    "    events = pd.read_csv(events_fn,delimiter='\\t')\n",
    "\n",
    "    t_r = 2.0 \n",
    "    #n_scans = epi.shape[-1]\n",
    "    n_scans = 156\n",
    "    frame_times = (np.arange(n_scans) * t_r)\n",
    "\n",
    "    X1 = make_first_level_design_matrix(frame_times,events,drift_model=\"polynomial\",drift_order=3,hrf_model=\"SPM\") #\n",
    "\n",
    "    #face_reg = X1['face'].values\n",
    "    #place_reg = X1[['body', 'house', 'object', 'scene', 'scramble']].values.sum(axis=1)\n",
    "\n",
    "    #face_reg = X1[['face','body']].values.sum(axis=1)\n",
    "    face_reg = X1[['face']].values.sum(axis=1)\n",
    "    place_reg = X1[['house','scene']].values.sum(axis=1)\n",
    "    \n",
    "    return face_reg,place_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c402a7e8-2bea-4ce6-b0f6-1925e1d70f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_corr2reg(epi,roi,reg,ofn):\n",
    "    epi_flat = epi.numpy().reshape(-1,epi.shape[-1])\n",
    "    gm_idx = roi.flatten()==1\n",
    "    std1_idx = epi_flat.std(axis=1)>1e-3\n",
    "    use_idx=gm_idx*std1_idx\n",
    "    voxel_array = epi_flat[use_idx,:]\n",
    "    voxel_array = (voxel_array-voxel_array.mean(axis=1)[:,np.newaxis]) / voxel_array.std(axis=1)[:,np.newaxis]\n",
    "    reg_arr = np.repeat(reg[:,np.newaxis], voxel_array.shape[0], axis=1)\n",
    "    corr_vals = correlate_columns(voxel_array.transpose(),reg_arr)\n",
    "    corr_arr = np.zeros(epi_flat.shape[0])\n",
    "    corr_arr[use_idx]=corr_vals\n",
    "    corr_nii = roi.new_image_like(corr_arr.reshape(roi.shape))\n",
    "    corr_nii.to_filename(ofn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4de5fdf3-f163-4b62-a9ff-dbc645824671",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [13:43<00:00, 58.85s/it]\n"
     ]
    }
   ],
   "source": [
    "for s in tqdm(np.random.permutation(np.arange(n))):\n",
    "    for r in [1,2,3,4]:\n",
    "        average_signal_maps(s,r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1167ccb4-0883-4d9a-9e03-44710af9f3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "gm_fn = '../Data/StudyForrest/fmriprep/mask_roi.nii'\n",
    "roi = ants.image_read(gm_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "78a5461b-36c5-489f-9058-83afedd007b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [01:28<00:00,  6.33s/it]\n"
     ]
    }
   ],
   "source": [
    "for s in tqdm(range(14)):\n",
    "    for r in [1,2,3,4]:\n",
    "        sub=subs[s]\n",
    "        face_reg,place_reg = get_regs(events_fn_temp.format(sub=sub,r=r))\n",
    "        epi = ants.image_read(os.path.join(analysis_dir,f'signal_S{s}_R{r}_med.nii.gz'))\n",
    "        map_corr2reg(epi,roi,face_reg,os.path.join(analysis_dir,f'signal-corr2face-S{s}_R{r}_med.nii.gz'))\n",
    "        map_corr2reg(epi,roi,place_reg,os.path.join(analysis_dir,f'signal-corr2place-S{s}_R{r}_med.nii.gz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "85526c70-01f6-44f1-a63d-82a74f1803f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:00<00:00, 28.61it/s]\n",
      "100%|██████████| 14/14 [00:00<00:00, 29.63it/s]\n"
     ]
    }
   ],
   "source": [
    "for s in tqdm(range(14)):\n",
    "    image_files = [ants.image_read(os.path.join(analysis_dir,f'signal-corr2face-S{s}_R{r}_med.nii.gz')) for r in [1,2,3,4]]\n",
    "    image_avg = image_files[0].new_image_like(np.array([image_file.numpy() for image_file in image_files]).mean(axis=0))\n",
    "    image_avg.to_filename(os.path.join(analysis_dir,f'signal-corr2face-S{s}_R_avg_med.nii.gz'))\n",
    "    \n",
    "for s in tqdm(range(14)):\n",
    "    image_files = [ants.image_read(os.path.join(analysis_dir,f'signal-corr2place-S{s}_R{r}_med.nii.gz')) for r in [1,2,3,4]]\n",
    "    image_avg = image_files[0].new_image_like(np.array([image_file.numpy() for image_file in image_files]).mean(axis=0))\n",
    "    image_avg.to_filename(os.path.join(analysis_dir,f'signal-corr2place-S{s}_R_avg_med.nii.gz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dd7b99fb-c294-4ef9-a0c1-7e05957f917a",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_files = [ants.image_read(os.path.join(analysis_dir,f'signal-corr2face-S{s}_R_avg_med.nii.gz')) for s in range(14)]\n",
    "image_avg =np.array([image_file.numpy() for image_file in image_files]).mean(axis=0)\n",
    "image_files[0].new_image_like(image_avg).to_filename(os.path.join(analysis_dir,f'signal-corr2face-grand_average_avg_med.nii.gz'))\n",
    "\n",
    "image_files = [ants.image_read(os.path.join(analysis_dir,f'signal-corr2place-S{s}_R_avg_med.nii.gz')) for s in range(14)]\n",
    "image_avg =np.array([image_file.numpy() for image_file in image_files]).mean(axis=0)\n",
    "image_files[0].new_image_like(image_avg).to_filename(os.path.join(analysis_dir,f'signal-corr2place-grand_average_avg_med.nii.gz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc627cff-55ab-45fa-acb3-aae3e8ae21bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86384320-76bd-47c1-a597-ef47361e603a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d482e3-298e-41d4-aa23-4274391cd809",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
